.. pyhrf documentation master file, created by
   sphinx-quickstart on Thu Jul 21 16:39:42 2011.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

**Welcome to pyhrf's documentation**
######################################


.. figure::  fMRI.png
   :align:   center

   **pyhrf**


This package aims at providing advanced tools for within-subject analysis in
event-related functional Magnetic Resonance Imaging (fMRI). Actually, our goal
is to detect and localize brain activations while estimating the HRF time course
in a spatially adaptive (ie parcel-based) GLM.

This package implements the Bayesian detection-estimation approach proposed in
[Makni05b, IEEE TSP] and its extensions developed in [Vincent 07, ICASSP,
EMBC]. The first paper is based on an independent mixture model (IMM) and
provides both a spatial activity map and an estimate of brain dynamics. In the
more recent contributions, we accounted for spatial correlation using a spatial
mixture model (SMM) based on a binary Markov random field.

**Licence, copyright**
#########################

This package is in a release version and can be distributed.
Please report any question to:
thomas.vincent@cea.fr, philippe.ciuciu@cea.fr or lotfi.chaari@inrialpes.fr

**Requirements / Dependencies**
###################################

Dependencies are:
    - :ref:`python` 2.5 or 2.6
    - :ref:`numpy` >= 1.0
    - :ref:`scipy` >= 0.7
    - :ref:`PyXML` >= 0.8.4
    - :ref:`pynifti`
    - :ref:`nibabel`
    - :ref:`python tables + hdf5` (dev) (for some outputs)

Optional dependencies:
    - matplotlib (viewer)
    - PyQt > 3.17 (viewer)
    - Qt + headers (widget for viewer)
    - pyro (distributed processing)

For performance issues, it is highly recommanded to use distribution specific
installations of numpy and scipy. These packages are widely distributed and
available on almost all linux platforms through their respective package manager
(yum, urpmi, apt-get, synaptic ...).

Instructions are given for python2.5, but work fine with python2.6 - adapt
pathes and replace python2.5 with python2.6 if you are using the latter.

.. _python:

*Python*
*********	

    - 1. Download the package `here <http://www.python.org/>`_.
    - 2. Uncompress the archive::

            $tar -zxvf /home/yourlogin/Desktop/Python-2.5.2.tgz
    - 3. Go to the installation directory::

            $cd /home/yourlogin/Python-2.5.2
    - 4. Configure::

	    $./configure

    - 5. Make::

           $make





More details about Python are available `here <http://www.python.org/>`_.

.. _scipy:

*Scipy*
***********	

**Ubuntu**::

$sudo apt-get install python-scipy


More details about Scipy are available `here <http://www.scipy.org/Installing_SciPy/Linux>`_.

.. _numpy:

*Numpy*
********	

**Ubuntu**::

$sudo apt-get install python-numpy 

More details about Numpy are available `here <http://www.scipy.org/Installing_SciPy/Linux>`_.

.. _PyXML:

*PyXML*
********	

More details about Python are available `here <http://www.python.org/>`_.

.. _pynifti:

*pynifti*
***********	

More details about Python are available `here <http://www.python.org/>`_.

.. _python tables + hdf5:

*Python tables + hdf5*
**************************	

More details about Python are available `here <http://www.python.org/>`_.

.. _nibabel:

*Nibabel*
**********

NiBabel is available via *pypi*.  If you already have setuptools or
distribute installed, you can run::

    $easy_install nibabel

to download nibabel and its dependencies.  Alternatively go to the *nibabel
pypi* page and select the source distribution you want.  Download the
distribution, unpack it, and then, from the unpacked directory, run::

    $python setup.py install

or (if you need root permission to install on a unix system)::

    $sudo python setup.py install

**Debian/Ubuntu**

NiBabel is available as a *NeuroDebian package*. Please follow the instructions
on the NeuroDebian website on how access their repositories. Once this is done,
installing NiBabel is::

  $apt-get update
  $apt-get install python-nibabel

.. _NeuroDebian package: http://neuro.debian.net/pkgs/python-nibabel.html

**Install from source**

If no installer or package is provided for your platfom, you can install
NiBabel from `source <http://pypi.python.org/pypi/nibabel>`_.


More details about Nibabel installation are available `here <http://nipy.sourceforge.net/nibabel/installation.html>`_.

.. automodule:: pyhrf.vbjde
    :members:
    :undoc-members:
    :inherited-members:
    :show-inheritance:
.. automodule:: pyhrf.jde
    :members:
    :undoc-members:
    :inherited-members:
    :show-inheritance:



More details about Numpy installation are available `here <http://numpy.scipy.org/>`_.

**Installation**
####################

The installation process relies on setuptools (overlay of distutils), 
therefore all python dependencies (numpy, scipy, PyXML, pynifti, matplotlib,
PyQt) should be "egg installed" if they are already installed. 
Sometimes python packages installed by the
system are not compatible with the setuptools egg system. Special installation
locations can be added to the ``'setup.cfg'`` file at the root directory of the pyhrf
decompressed tarball. Simply append a line such as:
``site-dirs=/path/to/installed/package``

If they are not present on the system, ``setup.py`` tries to download (therefore
needing an internet connection), compile and install python dependencies
automatically. For the compilation step, the following dependencies are
required:

     - gcc
     - fortran 95 compiler

**Distribution specificities**
***************************************


*Ubuntu*
++++++++++++++++++++++++++++

**Install dependencies**::

$sudo apt-get install python-dev python-setuptools python-tables python-numpy
$sudo apt-get install python-scipy python-matplotlib libhdf5-serial-dev 
$sudo apt-get install python-nifti pyro python-qt4 python-qt3

Refer to the :ref:`Pyhrf installation` section.

*Fedora*
+++++++++++++++++++++++++

**Install dependencies (as root)**::

$yum install gcc scipy numpy python-devel python-setuptools python-matplotlib
$yum install hdf5-devel PyQt4 PyQt 

For pynifti, you may have to manually install it. This process is documented `here <http://niftilib.sourceforge.net/pynifti/installation.html#installation>`_.

Refer to the :ref:`Pyhrf installation` section.



.. _Pyhrf installation:

**Pyhrf installation**
***************************************

You may have to repeat the install command ``$python setup.py ...`` several times for all dependencies to be properly downloaded and compiled.

In the directory where the pyhrf tarball has been decompressed:

- global installation::

     $python setup.py install 
    
 This will result in an attempt to write in the Python site-packages directory and will fail if you don't have the appropriate permissions (you usually need root privilege).
    
- local installation::

     $python setup.py install --prefix=/local/installation/path/

 Note: /local/installation/path/lib/python2.x/site-packages must exist and be in your ``PYTHONPATH`` environment variable. Pyhrf executables will be installed in /my/directory/bin/ so that the latter should be in the ``PATH`` environment variable.


*** use mode:**

To unlock in-development features, append *-u devel* to the ``$python setup.py ...`` command.	


*** Run tests to check installation:**

$pyhrf_maketests

*** Develop mode:**

Installation in develop mode (only links to the source tree are installed),
custom install location, development use mode: ``$python setup.py develop --prefix=/home/user/local -u devel``

**Using pyhrf**
################

Using pyhrf is made up of 4 main steps:

    - 1. :ref:`parcellation`
    - 2. :ref:`Treatment configuration`
    - 3. :ref:`Running the joint detection-estimation proces`
    - 4. :ref:`Output results`

Pyhrf also offers you possibility to use the MCMC methods or the VEM algorithm for the inference. Comparisons between the two methods are therefore possible, in addition to comparisons with GLM-based methods like SPM when the estimation task is turned off with pyhrf.

.. _parcellation:

**Parcellation**
******************

You may either produce a suitable ROI parcellation from SPM (marsbar) or use nipy which can produce a parcellation computed from statistics produced by SPM (betas, constrasts, ...). 

.. _Treatment configuration:

**Treatment configuration**
*****************************

*MCMC*
++++++++

Information needed by a Pyhrf treatment for one session is: the BOLD 4D data, a parcellation (= a 3D volume of labels defining the ROIs), a set of stimulus names associated to onset sequences. Configuration of pyhrf is made through the edition of a xml file. At first, generate a template of this file by issuing:: 

$pyhrf_jde_buildcfg 

A file detectestim.xml is then created. By default, it contains the definition of a treatment over data included in the Pyhrf distribution (i.e. localizer experiment). It serves as example to build a customized treatment. 
This file is organised as follows:

.. figure::  xml_setup_data.gif
   :align:   center

   **Generated XML file**

The SessionsParams section describes all fMRI sessions. Each child tag stands for each session, by default only one session indexed by i0. If you have to append other session data, index them by i1,i2, and so on. Down one level, the definition of one session is made of: 

    - stimulusLength, which must be consistent with onsets and define the stimulus durations in seconds. If empty, then peaked stimuli are considered.
    - onsets, which stores the different stimuli types with their time arrivals. Every stimulus designation must be unique. The sequence associated to each stimulus designation is the set of time arrivals in seconds, separated by one space delimiter.
    - fMRIDataFile, which indicates the location of the BOLD data. Supported formats: nifti, analyse.

Following SessionsParams, there are parameters that describe data and are common to all sessions:

    - TimeOfRepetition (expressed in seconds) defines the temporal resolution of the BOLD signal (number of scans).
    - regionIds, a list of integers being the list of parcel label to limit the analysis to.
    - parcellationFile, which indicates the location of the mask defining ROIs: a volume of labels (integers) where 0 is the background.
    - treatedParcellationFile, the file to write the treated functional mask. May be different from the input mask if some BOLD signals have NAN values or null variance, for example.

After the definition of data inputs in SessionsParams, one can define the minimal number of voxels in a ROI. ROIs which do not verify this condition are discarded.
The last part analyser groups all parameters for the actual analysis. The contrasts have to be defined in analyse/responseLevels/constrast, following the format: ``condition1-condion2;condition3-condition1;``. Note that condition labels must be consistent with those entered in the data definition part. See contextual comments within the xml for more information on other parameters. 


*VEM*
++++++++

.. _Running the joint detection-estimation proces:

**Running the joint detection-estimation proces**
***************************************************

To run the pyhrf treatment defined in ``detectestim.xml`` ::

$pyhrf_jde_estim -v1

Here ``-v1`` stands for the level of verbosity (from 0: quiet, to 6: everything - only for debug purpose).




.. _Output results:

**Output results**
********************

**Outputs**:

    - Contrast maps: contrast maps are generated according to the definition of ``fMRITreatmentParameters/analyser/BoldEstimationModel/responseLevels/contrasts/`` in the xml file. Output file format is: ``pm_nrl_con_<contrast_name>.nii``
    - Contrast variance maps: associated to every contrast maps, these files are in the form: ``pm_nrl_convar_<contrast_name>.nii``
    - hemodynamic response: to each voxel, a normalised estimated HRF is affected: the one estimated for the region comprising this voxel. Estimated HRF are then duplicated. Note that one HRF is common to all conditions.
      The output file is: ``pm_hrf.nii``
    - Neural response levels maps: for each condition, estimated NRL are stored in files of the form: ``pm_nrl_condition_<condition_name>.nii``

A JDE specific file is generated (by default ``jde_outputs.xml``) which gathers all paths to output images with some additional information. This file is intended to be used as input of ``pyhrf_view`` (see next part). 

**Viewer**:

A dedicated viewer is available. To view results from a JDE analysis, the simplest way is to type the following command within the directory where the JDE outputs are::

$pyhrf_view jde_outputs.xml

A window shows all loaded files: 


.. figure::  viewer_obj_browser.png
   :align:   center


Double-clicking on an item opens two windows:

    - A browser that controls the current slice: 

	- View Mode selects the dimension of the slice.
   	- Crop to mask is a useless option.
        - Current Axes select which axes form the current slice.
        - For each axis there is a slicer.

.. figure::  viewer_axis_browser.png
   :align:   center

.

    - A graphic window, which displays data from the slice defined by the browser: 
        
.. figure::  viewer_graphic_window.png
   :align:   center

**Classes and methods**
########################


	
**VEM**
********

.. automodule:: pyhrf.vbjde.Utils
   :members: mult , polyFit,PolyMat

.. _MCMC:

**MCMC**
********
ddsds

.. automodule:: pyhrf.jde.hrf
   :members: 

**Indices and tables**
#######################

* :ref:`genindex`
* :ref:`modindex`
* :ref:`search`

